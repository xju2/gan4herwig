{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc2c6413-93d1-4902-82af-2c9babb8c5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# %load_ext tensorboard\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1);\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "from utils import create_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d7e7cbd-ee30-4a97-b4da-eeeadcbebc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/global/home/users/xju/projects/herwig/data\"\n",
    "filename = os.path.join(data_path, \"allHadrons_10M_mode4_with_quark_with_pert.npz\")\n",
    "org_filename = os.path.join(data_path, \"cluster_ML_allHadrons_10M.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f484ca-23d6-4791-95fa-df101a707209",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Hadron types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7cad65f-aa9b-4936-ab9c-098edefec2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_dataframe, split_to_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "836be6e8-18fc-49a8-9338-dd7656a0529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_dataframe(org_filename, \";\", 'python')\n",
    "q1,q2,c,h1,h2 = [split_to_float(df[idx]) for idx in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5b269dd-04b5-45dd-b879-efba46c0d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_type, h2_type = h1[[0]], h2[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f5f51af-191e-4a5b-b899-de7119b44b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 16\n",
    "def plot_counts(array: np.ndarray):\n",
    "    types, counts = np.unique(array, return_counts=True)\n",
    "    num_types = len(types)\n",
    "    tot_cnts = np.sum(counts)\n",
    "    xvals = np.arange(num_types)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ax.scatter(xvals, counts/tot_cnts, s=2.)\n",
    "\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_xlabel(\"hadron type\", fontsize=fontsize)\n",
    "    print(f\"total {num_types} hadrons in the final state\")\n",
    "    return types.astype(np.int64), num_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee027507-0357-417b-b076-078cddd7cccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 322 hadrons in the final state\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hadron_types = plot_counts(np.concatenate([h1_type, h2_type], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d7e448-c124-4052-a55c-98865e8b8589",
   "metadata": {},
   "source": [
    "## Hadron type embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1011109-8705-4ad4-bdb1-4d336ed37abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 10\n",
    "hadron_pids, num_hadron_types = hadron_types\n",
    "pids_to_ix = {pids: i for i, pids in enumerate(hadron_pids)}\n",
    "\n",
    "pickle.dump(pids_to_ix, open(\"pids_to_ix.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bbbe0303-376b-4c24-aff4-93511b6ebc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_embedding = nn.Embedding(num_hadron_types, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "42f9a87c-c24f-4ac5-9b39-ca201d441171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4865, -0.2672, -0.9057,  1.1978, -1.4437,  0.1671, -0.9476,  0.2961,\n",
      "         -0.0076, -2.0869]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lookup_tensor = torch.tensor([pids_to_ix[111]], dtype=torch.long)\n",
    "pion_embed = type_embedding(lookup_tensor)\n",
    "print(pion_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e8a63",
   "metadata": {},
   "source": [
    "# GAN with hadron type embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ab1b3d",
   "metadata": {},
   "source": [
    "Read the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3936ef78-3d0a-44d8-b1b4-d09a0084ce39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78984075, 4) (78984075, 8)\n",
      "CPU times: user 2min 46s, sys: 1.79 s, total: 2min 47s\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 10000\n",
    "num_workers = 6\n",
    "\n",
    "train_loader, test_loader, xlabels = create_dataloader(filename, batch_size, num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec0a932-b1ea-4277-92ba-09f18ee8b92d",
   "metadata": {},
   "source": [
    "Read in the particle index map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d322931b-2a0d-4d20-bf05-433ae2615436",
   "metadata": {},
   "outputs": [],
   "source": [
    "pids_to_ix = pickle.load(open(\"pids_to_ix.pkl\", \"rb\"))\n",
    "num_hadron_types = len(list(pids_to_ix.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4970915-bfc7-4af9-8745-ebb05249bd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional dimension:  8\n",
      "output dimension:  2\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "cond_dim = batch[0].shape[1]\n",
    "output_dim = batch[1].shape[1] - 2\n",
    "print(\"conditional dimension: \", cond_dim)\n",
    "print(\"output dimension: \", output_dim)\n",
    "\n",
    "trained_models = \"all_hadron_v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "50214b10-3b8e-4195-a53c-088946809bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_MLP_layers(input_dim: int, output_dim: int,\n",
    "               num_layers: int, hidden_dim: int,\n",
    "               dropout: float = 0.2,\n",
    "               layer_norm: bool = True):\n",
    "    layer_list = []\n",
    "    for i in range(num_layers):\n",
    "        if i == 0:\n",
    "            layer_list.append(torch.nn.Linear(input_dim, hidden_dim))\n",
    "        else:\n",
    "            layer_list.append(torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "\n",
    "        if layer_norm:\n",
    "            layer_list.append(torch.nn.LayerNorm(hidden_dim))\n",
    "\n",
    "        layer_list.append(torch.nn.LeakyReLU(0.2))\n",
    "        if dropout > 0:\n",
    "            layer_list.append(torch.nn.Dropout(dropout))\n",
    "\n",
    "    layer_list.append(torch.nn.Linear(hidden_dim, output_dim))\n",
    "    return layer_list\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \"\"\"Generator for the GAN\"\"\"\n",
    "    def __init__(self, noise_dim: int, cond_dim: int, output_dim: int,\n",
    "                 num_hadron_types: int, num_layers: int, hidden_dim: int,\n",
    "                 num_max_hadrons: int = 2,\n",
    "                 dropout: float = 0,\n",
    "                 layer_norm: bool = True,\n",
    "                ):       \n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        layer_list = create_MLP_layers(\n",
    "            noise_dim + cond_dim,\n",
    "            output_dim+num_hadron_types*num_max_hadrons,\n",
    "            num_layers, hidden_dim, dropout)\n",
    "\n",
    "        self.model = nn.Sequential(*layer_list)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n",
    "class Discriminator(torch.nn.Module):\n",
    "    \"\"\"Discriminator for the GAN\"\"\"\n",
    "    def __init__(self, input_dim: int, cond_dim: int,\n",
    "                 num_hadron_types: int, \n",
    "                 num_layers: int, hidden_dim: int,\n",
    "                 num_max_hadrons: int = 2,\n",
    "                 dropout: float = 0.2,\n",
    "                 layer_norm: bool = True,\n",
    "                ):\n",
    "        super(Discriminator, self).__init__()        \n",
    "        \n",
    "        layer_list = create_MLP_layers(\n",
    "            cond_dim + input_dim +  num_hadron_types * num_max_hadrons,\n",
    "            1,\n",
    "            num_layers, hidden_dim, dropout, layer_norm)\n",
    "\n",
    "        layer_list.append(nn.Sigmoid())\n",
    "        self.model = torch.nn.Sequential(*layer_list)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ae68414-72b3-4364-ab86-9b0ac50eea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HPs for the GAN\n",
    "noise_dim = 16\n",
    "num_max_hadrons = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "52bb776c-37a4-465b-a6f6-fccc8b8d5b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=24, out_features=1024, bias=True)\n",
      "    (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (4): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "    (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (7): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (8): LeakyReLU(negative_slope=0.2)\n",
      "    (9): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (10): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (11): LeakyReLU(negative_slope=0.2)\n",
      "    (12): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (13): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (14): LeakyReLU(negative_slope=0.2)\n",
      "    (15): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (16): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (17): LeakyReLU(negative_slope=0.2)\n",
      "    (18): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (19): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (20): LeakyReLU(negative_slope=0.2)\n",
      "    (21): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (22): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (23): LeakyReLU(negative_slope=0.2)\n",
      "    (24): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (25): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (26): LeakyReLU(negative_slope=0.2)\n",
      "    (27): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (28): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    (29): LeakyReLU(negative_slope=0.2)\n",
      "    (30): Linear(in_features=1024, out_features=646, bias=True)\n",
      "  )\n",
      ")\n",
      "Discriminator(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=654, out_features=64, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2)\n",
      "    (8): Dropout(p=0.2, inplace=False)\n",
      "    (9): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2)\n",
      "    (11): Dropout(p=0.2, inplace=False)\n",
      "    (12): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (13): LeakyReLU(negative_slope=0.2)\n",
      "    (14): Dropout(p=0.2, inplace=False)\n",
      "    (15): Linear(in_features=64, out_features=1, bias=True)\n",
      "    (16): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "generator = Generator(noise_dim, cond_dim, output_dim, num_hadron_types,\n",
    "                      num_layers=10, hidden_dim=1024,\n",
    "                      num_max_hadrons=num_max_hadrons).to(device)\n",
    "\n",
    "discriminator = Discriminator(output_dim, cond_dim, num_hadron_types,\n",
    "                              num_layers=5, hidden_dim=64,\n",
    "                              num_max_hadrons=num_max_hadrons, layer_norm=False).to(device)\n",
    "\n",
    "print(generator)\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0333b70-60e9-4a9a-a54d-4a8d11a4cfbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e037e5c6-01cb-404b-bac6-8d338c619407",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "noise = torch.randn(batch_size, noise_dim).to(device)\n",
    "x, y = batch\n",
    "x, y = x.to(device), y.to(device)\n",
    "x_gen = torch.concat([x, noise], dim=1).to(device)\n",
    "\n",
    "fake = generator(x_gen)\n",
    "\n",
    "x_disc = torch.cat([x, fake], dim=1).to(device)\n",
    "score = discriminator(x_disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e783f330-55f8-4ec7-9019-3f590d399965",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss functions\n",
    "\n",
    "criterion = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f70538d9-7362-4286-a64b-e900a1c348d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HPs for training\n",
    "gen_lr  = 0.00001\n",
    "disc_lr = 0.00005\n",
    "beta1 = 0.5   # default value: 0.9\n",
    "\n",
    "opt_gen = optim.Adam(generator.parameters(), lr=gen_lr, betas=(beta1, 0.999))\n",
    "opt_disc = optim.Adam(discriminator.parameters(), lr=disc_lr, betas=(beta1, 0.999))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ec66a768-3c67-4960-9467-7fd002eb8846",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "    \n",
    "    tot_loss_gen = 0\n",
    "    tot_loss_disc = 0\n",
    "    num_batches = 0\n",
    "    for batch in train_loader:\n",
    "        num_batches += 1\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        ##  Train discriminator with all-real batch\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        target_hadron_types = y[:, 2:].reshape(-1).long()\n",
    "        target_hadron_types_idx = torch.from_numpy(np.array(\n",
    "            [pids_to_ix[int(pid)] for pid in target_hadron_types]))\n",
    "        \n",
    "        num_evts = y.shape[0]\n",
    "\n",
    "        true_hadron_types = torch.abs(F.one_hot(target_hadron_types_idx, num_classes=num_hadron_types) \\\n",
    "            - torch.rand(num_evts*num_max_hadrons, num_hadron_types)*0.001).reshape(num_evts, -1).to(device)\n",
    "        x_truth = torch.cat([x, y[:, :2], true_hadron_types], dim=1)\n",
    "        score_truth = discriminator(x_truth).squeeze()\n",
    "        label = torch.full((num_evts,), real_label, dtype=torch.float, device=device)\n",
    "        loss_real = criterion(score_truth, label)\n",
    "\n",
    "        loss_real.backward()\n",
    "\n",
    "        ## Train discriminator with all-fake batch\n",
    "        noise = torch.randn(num_evts, noise_dim).to(device)\n",
    "        x_fake = torch.concat([x, noise], dim=1)\n",
    "        fake = generator(x_fake)\n",
    "\n",
    "        x_generated = torch.cat([x, fake], dim=1)\n",
    "        score_fakes = discriminator(x_generated.detach()).squeeze()\n",
    "        label.fill_(fake_label)\n",
    "        loss_fake = criterion(score_fakes, label)\n",
    "        loss_fake.backward()\n",
    "        loss_disc = loss_real + loss_fake\n",
    "        ## Update discriminator\n",
    "        opt_disc.step()\n",
    "\n",
    "\n",
    "        ## Train generator\n",
    "        generator.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "        score_fakes = discriminator(x_generated).squeeze()\n",
    "        loss_generator = criterion(score_fakes, label)\n",
    "        loss_generator.backward()\n",
    "        opt_gen.step()\n",
    "        \n",
    "        tot_loss_gen += loss_generator.item()\n",
    "        tot_loss_disc += loss_disc.item()\n",
    "        \n",
    "        if num_batches > 10000:\n",
    "            break\n",
    "        \n",
    "    return tot_loss_gen/num_batches, tot_loss_disc/num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f8027893-9194-4aca-9c9c-6c4a08d1ca85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_batch(batch):\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "    \n",
    "    x, y = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "\n",
    "    ##  Train discriminator with all-real batch\n",
    "    discriminator.zero_grad()\n",
    "\n",
    "    target_hadron_types = y[:, 2:].reshape(-1).long()\n",
    "    target_hadron_types_idx = torch.from_numpy(np.array(\n",
    "        [pids_to_ix[int(pid)] for pid in target_hadron_types]))\n",
    "\n",
    "    num_evts = y.shape[0]\n",
    "\n",
    "    true_hadron_types = torch.abs(F.one_hot(target_hadron_types_idx, num_classes=num_hadron_types) \\\n",
    "        - torch.rand(num_evts*num_max_hadrons, num_hadron_types)*0.001).reshape(num_evts, -1).to(device)\n",
    "    x_truth = torch.cat([x, y[:, :2], true_hadron_types], dim=1)\n",
    "    score_truth = discriminator(x_truth).squeeze()\n",
    "    label = torch.full((num_evts,), real_label, dtype=torch.float, device=device)\n",
    "    loss_real = criterion(score_truth, label)\n",
    "\n",
    "    loss_real.backward()\n",
    "\n",
    "    ## Train discriminator with all-fake batch\n",
    "    noise = torch.randn(num_evts, noise_dim).to(device)\n",
    "    x_fake = torch.concat([x, noise], dim=1)\n",
    "    fake = generator(x_fake)\n",
    "\n",
    "    x_generated = torch.cat([x, fake], dim=1)\n",
    "    score_fakes = discriminator(x_generated.detach()).squeeze()\n",
    "    label.fill_(fake_label)\n",
    "    loss_fake = criterion(score_fakes, label)\n",
    "    loss_fake.backward()\n",
    "    loss_disc = loss_real + loss_fake\n",
    "    ## Update discriminator\n",
    "    opt_disc.step()\n",
    "\n",
    "\n",
    "    ## Train generator\n",
    "    generator.zero_grad()\n",
    "    label.fill_(real_label)\n",
    "    score_fakes = discriminator(x_generated).squeeze()\n",
    "    loss_generator = criterion(score_fakes, label)\n",
    "    loss_generator.backward()\n",
    "    opt_gen.step()\n",
    "        \n",
    "    return loss_generator.item(), loss_disc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8030b631-bafd-4a20-8a10-38001895afe1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/home/users/xju/miniconda3/envs/pyG-1.12.1/lib/python3.9/site-packages/torch/_tensor.py:1083: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484806139/work/build/aten/src/ATen/core/TensorBody.h:477.)\n",
      "  return self._grad\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "writer.add_graph(generator, x_gen)\n",
    "writer.add_graph(discriminator, x_disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e60a286-e178-4196-9ac4-5c48937e0c5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0:  29%|██▉       | 2070/7109 [14:41<35:45,  2.35it/s, lossG=0.693, lossD=0.693] \n",
      "  0%|          | 0/200 [14:46<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [51], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28menumerate\u001b[39m(train_loader), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, total\u001b[38;5;241m=\u001b[39mnum_batches) \u001b[38;5;28;01mas\u001b[39;00m t1:\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m bidx,batch \u001b[38;5;129;01min\u001b[39;00m t1:\n\u001b[0;32m----> 8\u001b[0m         loss_gen, loss_disc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m         metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lossG\u001b[38;5;241m=\u001b[39mloss_gen, lossD\u001b[38;5;241m=\u001b[39mloss_disc\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     11\u001b[0m         t1\u001b[38;5;241m.\u001b[39mset_postfix(metric)\n",
      "Cell \u001b[0;32mIn [45], line 13\u001b[0m, in \u001b[0;36mtrain_one_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m discriminator\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     11\u001b[0m target_hadron_types \u001b[38;5;241m=\u001b[39m y[:, \u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     12\u001b[0m target_hadron_types_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m---> 13\u001b[0m     [pids_to_ix[\u001b[38;5;28mint\u001b[39m(pid)] \u001b[38;5;28;01mfor\u001b[39;00m pid \u001b[38;5;129;01min\u001b[39;00m target_hadron_types]))\n\u001b[1;32m     15\u001b[0m num_evts \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m true_hadron_types \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(F\u001b[38;5;241m.\u001b[39mone_hot(target_hadron_types_idx, num_classes\u001b[38;5;241m=\u001b[39mnum_hadron_types) \\\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(num_evts\u001b[38;5;241m*\u001b[39mnum_max_hadrons, num_hadron_types)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(num_evts, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn [45], line 13\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m discriminator\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     11\u001b[0m target_hadron_types \u001b[38;5;241m=\u001b[39m y[:, \u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     12\u001b[0m target_hadron_types_idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m---> 13\u001b[0m     [pids_to_ix[\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m] \u001b[38;5;28;01mfor\u001b[39;00m pid \u001b[38;5;129;01min\u001b[39;00m target_hadron_types]))\n\u001b[1;32m     15\u001b[0m num_evts \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m true_hadron_types \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(F\u001b[38;5;241m.\u001b[39mone_hot(target_hadron_types_idx, num_classes\u001b[38;5;241m=\u001b[39mnum_hadron_types) \\\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand(num_evts\u001b[38;5;241m*\u001b[39mnum_max_hadrons, num_hadron_types)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(num_evts, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "num_batches = len(train_loader)\n",
    "\n",
    "for _ in tqdm.trange(num_epochs, position=1):\n",
    "    # training\n",
    "    with tqdm.tqdm(enumerate(train_loader), desc=f\"Epoch {_}\", position=0, leave=True, total=num_batches) as t1:\n",
    "        for bidx,batch in t1:\n",
    "            loss_gen, loss_disc = train_one_batch(batch)\n",
    "\n",
    "            metric = dict(lossG=loss_gen, lossD=loss_disc/2)\n",
    "            t1.set_postfix(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5fb57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'generator': generator.state_dict(),\n",
    "            'discriminator': discriminator.state_dict(),\n",
    "            'generator_opt': opt_gen.state_dict(),\n",
    "            'discriminator_opt': opt_disc.state_dict()\n",
    "           }, f'{trained_models}.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a6c86-8d15-48e5-9f30-13866efc6ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a517b4ca-f476-452d-b7f1-18483745ea4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe18a8-babf-4b52-b360-ff4bfbd75a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # writer.add_scalar(\"Generator Loss\", loss_gen, _)\n",
    "        # writer.add_scalar(\"Discriminator Loss\", loss_disc, _)\n",
    "        \n",
    "            \n",
    "        \n",
    "            # validation <TODO>\n",
    "            # t0.set_postfix(**metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "22bc0038c9d8ff767a88afaae49674e591625273f43cd41c2a84bf36af7b0d28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
